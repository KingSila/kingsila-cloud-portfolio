name: Deploy AKS (Helm-Test)

on:
  workflow_dispatch:
    inputs:
      environment:
        description: "Environment to deploy"
        required: true
        type: choice
        options: [dev, test]

permissions:
  id-token: write
  contents: read

defaults:
  run:
    shell: bash

env:
  RG_DEV: rg-kingsila-dev
  AKS_DEV: aks-kingsila-dev
  RG_TEST: rg-kingsila-test
  AKS_TEST: aks-kingsila-test
  HELM_RELEASE: golden-app

jobs:
  deploy:
    runs-on: [self-hosted, linux]

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Azure Login (OIDC)
        uses: azure/login@v2
        with:
          client-id: ${{ secrets.AZURE_CLIENT_ID }}
          tenant-id: ${{ secrets.AZURE_TENANT_ID }}
          subscription-id: ${{ secrets.AZURE_SUBSCRIPTION_ID }}

      - name: Show Azure account info
        run: |
          set -euo pipefail
          az account show --query "{user:user.name, type:user.type, tenant:tenantId, sub:id}" -o jsonc
          az account get-access-token --resource https://management.azure.com/ --query "expiresOn" -o tsv

      - name: Select cluster vars
        run: |
          set -euo pipefail
          ENV="${{ inputs.environment }}"

          if [ "$ENV" = "dev" ]; then
            echo "RG=${RG_DEV}" >> "$GITHUB_ENV"
            echo "AKS=${AKS_DEV}" >> "$GITHUB_ENV"
            echo "WI_CLIENT_ID=${{ secrets.WI_APP_DEV_CLIENT_ID }}" >> "$GITHUB_ENV"
          else
            echo "RG=${RG_TEST}" >> "$GITHUB_ENV"
            echo "AKS=${AKS_TEST}" >> "$GITHUB_ENV"
            echo "WI_CLIENT_ID=${{ secrets.WI_APP_TEST_CLIENT_ID }}" >> "$GITHUB_ENV"
          fi

          echo "ENV_NAME=$ENV" >> "$GITHUB_ENV"

      - name: Debug selected vars
        run: |
          set -euo pipefail
          echo "RG=${RG:-<missing>}"
          echo "AKS=${AKS:-<missing>}"
          echo "ENV_NAME=${ENV_NAME:-<missing>}"
          echo "HELM_RELEASE=${HELM_RELEASE:-<missing>}"
          echo "WI_CLIENT_ID=${WI_CLIENT_ID:-<missing>}"

      - name: Guard RG/AKS set
        run: |
          set -euo pipefail
          : "${RG:?missing RG}"
          : "${AKS:?missing AKS}"

      - name: Install kubectl + kubelogin (no sudo, hardened)
        shell: bash
        run: |
          set -euo pipefail

          echo "Who am I?"
          id
          echo "RUNNER_TEMP=$RUNNER_TEMP"
          echo "GITHUB_WORKSPACE=$GITHUB_WORKSPACE"
          df -h || true

          BIN_DIR="$RUNNER_TEMP/bin"
          mkdir -p "$BIN_DIR"
          echo "$BIN_DIR" >> "$GITHUB_PATH"

          # --- kubectl ---
          KVER="$(curl -fsSL https://dl.k8s.io/release/stable.txt)"
          echo "Installing kubectl $KVER"
          curl -fSL --retry 5 --retry-delay 2 -o "$RUNNER_TEMP/kubectl" \
            "https://dl.k8s.io/release/${KVER}/bin/linux/amd64/kubectl"
          chmod +x "$RUNNER_TEMP/kubectl"
          mv "$RUNNER_TEMP/kubectl" "$BIN_DIR/kubectl"

          # --- kubelogin ---
          KLOGIN_VER="$(curl -fsSL https://api.github.com/repos/Azure/kubelogin/releases/latest | grep -m1 '"tag_name":' | cut -d'"' -f4)"
          echo "Installing kubelogin $KLOGIN_VER"
          curl -fSL --retry 5 --retry-delay 2 -o "$RUNNER_TEMP/kubelogin.zip" \
            "https://github.com/Azure/kubelogin/releases/download/${KLOGIN_VER}/kubelogin-linux-amd64.zip"
          unzip -o "$RUNNER_TEMP/kubelogin.zip" -d "$RUNNER_TEMP/kubelogin"
          mv "$RUNNER_TEMP/kubelogin/bin/linux_amd64/kubelogin" "$BIN_DIR/kubelogin"
          chmod +x "$BIN_DIR/kubelogin"

          kubectl version --client
          kubelogin --version

      - name: AKS creds + Helm deploy (test)
        shell: bash
        env:
          KUBECONFIG: ${{ runner.temp }}/kubeconfig
        run: |
          set -euo pipefail

          az aks get-credentials -g rg-kingsila-test -n aks-kingsila-test --file "$KUBECONFIG" --overwrite-existing
          kubelogin convert-kubeconfig -l azurecli --kubeconfig "$KUBECONFIG"

          kubectl --kubeconfig "$KUBECONFIG" get nodes

          cd infra/k8s/golden-app/charts
          helm --kubeconfig "$KUBECONFIG" -n test upgrade --install golden-app . -f values.yaml -f values-test.yaml

          kubectl --kubeconfig "$KUBECONFIG" -n test get pods

      - name: Setup Helm
        uses: azure/setup-helm@v4
        with:
          version: latest

      - name: Helm upgrade (test)
        env:
          KUBECONFIG: ${{ runner.temp }}/kubeconfig
        run: |
          cd infra/k8s/golden-app/charts
          helm upgrade --install golden-app . -n test -f values.yaml -f values-test.yaml
          helm -n test list
          kubectl -n test get pods

      # -----------------------------------------------------------------------
      # Helper: robust AKS Run Command wrapper (AKS_RUN)
      # -----------------------------------------------------------------------
      - name: Install aks_run helper
        run: |
          set -euo pipefail

          mkdir -p "${RUNNER_TEMP}"
          test -w "${RUNNER_TEMP}"

          # JSON parser
          cat > "${RUNNER_TEMP}/aks_run_parse.py" <<'PY'
          import json, sys
          raw = sys.stdin.read()
          obj = json.loads(raw)
          logs = obj.get("logs") or ""
          print(str(logs).rstrip())
          PY

          # Bash wrapper
          cat > "${RUNNER_TEMP}/aks_run" <<'BASH'
          #!/usr/bin/env bash
          set -euo pipefail
          : "${RG:?RG env var is required}"
          : "${AKS:?AKS env var is required}"
          : "${RUNNER_TEMP:?RUNNER_TEMP env var is required}"

          if [ "$#" -lt 1 ]; then
            echo "Usage: aks_run <command...>" >&2
            exit 2
          fi

          cmd="$*"
          out="$(az aks command invoke --only-show-errors -g "${RG}" -n "${AKS}" --command "${cmd}" -o json)"
          printf "%s" "${out}" | python3 "${RUNNER_TEMP}/aks_run_parse.py"
          BASH

          chmod +x "${RUNNER_TEMP}/aks_run"
          echo "AKS_RUN=${RUNNER_TEMP}/aks_run" >> "$GITHUB_ENV"

          echo "Created runner helper:"
          ls -la "${RUNNER_TEMP}/aks_run" "${RUNNER_TEMP}/aks_run_parse.py"
          /usr/bin/env bash -n "${RUNNER_TEMP}/aks_run"

      # -----------------------------------------------------------------------
      # Cluster bootstrap
      # -----------------------------------------------------------------------
      - name: Ensure namespace exists (dev/test)
        run: |
          set -euo pipefail
          "$AKS_RUN" kubectl get ns "${ENV_NAME}" >/dev/null 2>&1 || true
          "$AKS_RUN" "kubectl get ns ${ENV_NAME} >/dev/null 2>&1 || kubectl create ns ${ENV_NAME}"

      - name: Install NGINX ingress controller (test)
        if: ${{ inputs.environment == 'test' }}
        run: |
          set -euo pipefail
          az aks command invoke \
            -g "${RG}" \
            -n "${AKS}" \
            --file "infra/k8s/system/install-ingress-nginx.sh" \
            --command "set -euxo pipefail; ls -la; bash ./install-ingress-nginx.sh"

      - name: Apply NetworkPolicy default-deny-all (test)
        if: ${{ inputs.environment == 'test' }}
        run: |
          set -euo pipefail
          az aks command invoke \
            -g "${RG}" \
            -n "${AKS}" \
            --file infra/k8s/overlays/test/networkpolicy-default-deny.yaml \
            --command "kubectl apply -f networkpolicy-default-deny.yaml"

      - name: Apply NetworkPolicy allow-dns-egress (test)
        if: ${{ inputs.environment == 'test' }}
        run: |
          set -euo pipefail
          az aks command invoke \
            -g "${RG}" \
            -n "${AKS}" \
            --file infra/k8s/overlays/test/networkpolicy-allow-dns-egress.yaml \
            --command "kubectl apply -f networkpolicy-allow-dns-egress.yaml"

      - name: Create extra NetworkPolicy files (test)
        if: ${{ inputs.environment == 'test' }}
        run: |
          set -euo pipefail

          cat > "$RUNNER_TEMP/networkpolicy-allow-egress-within-test.yaml" <<'YAML'
          apiVersion: networking.k8s.io/v1
          kind: NetworkPolicy
          metadata:
            name: allow-egress-within-test
            namespace: test
          spec:
            podSelector: {}
            policyTypes:
            - Egress
            egress:
            - to:
              - podSelector: {}
          YAML

          cat > "$RUNNER_TEMP/networkpolicy-allow-test-to-app.yaml" <<'YAML'
          apiVersion: networking.k8s.io/v1
          kind: NetworkPolicy
          metadata:
            name: allow-test-to-app
            namespace: test
          spec:
            podSelector:
              matchLabels:
                app.kubernetes.io/instance: golden-app
            policyTypes:
            - Ingress
            ingress:
            - from:
              - podSelector: {}
              ports:
              - protocol: TCP
                port: 8080
          YAML

      - name: Apply NetworkPolicy allow-egress-within-namespace (test)
        if: ${{ inputs.environment == 'test' }}
        run: |
          set -euo pipefail
          az aks command invoke \
            -g "${RG}" \
            -n "${AKS}" \
            --file "${RUNNER_TEMP}/networkpolicy-allow-egress-within-test.yaml" \
            --command "kubectl apply -f networkpolicy-allow-egress-within-test.yaml"

      - name: Apply NetworkPolicy allow-test-to-app (test)
        if: ${{ inputs.environment == 'test' }}
        run: |
          set -euo pipefail
          az aks command invoke \
            -g "${RG}" \
            -n "${AKS}" \
            --file "${RUNNER_TEMP}/networkpolicy-allow-test-to-app.yaml" \
            --command "kubectl apply -f networkpolicy-allow-test-to-app.yaml"

      - name: Apply NetworkPolicy allow-ingress-nginx-to-app (test)
        if: ${{ inputs.environment == 'test' }}
        run: |
          set -euo pipefail
          az aks command invoke \
            -g "${RG}" \
            -n "${AKS}" \
            --file infra/k8s/overlays/test/networkpolicy-allow-ingress-nginx-to-app.yaml \
            --command "kubectl apply -f networkpolicy-allow-ingress-nginx-to-app.yaml"

      # --------------------------
      # Helm render gate (runner)
      # --------------------------
      - name: Helm render validation (runner)
        run: |
          set -euo pipefail
          helm template "${HELM_RELEASE}" ./infra/k8s/golden-app/charts \
            --namespace "${ENV_NAME}" \
            -f ./infra/k8s/golden-app/charts/values.yaml \
            -f ./infra/k8s/${ENV_NAME}/values.yaml \
            --set workloadIdentity.clientId="${WI_CLIENT_ID}" \
            --debug > /dev/null

      # --------------------------
      # Render Helm chart to manifests (runner) + Apply (in-cluster)
      # --------------------------
      - name: Render Helm chart to manifests (runner)
        run: |
          set -euo pipefail
          OUT_FILE="$RUNNER_TEMP/helm-rendered.yaml"

          helm template "${HELM_RELEASE}" ./infra/k8s/golden-app/charts \
            --namespace "${ENV_NAME}" \
            -f ./infra/k8s/golden-app/charts/values.yaml \
            -f ./infra/k8s/${ENV_NAME}/values.yaml \
            --set workloadIdentity.clientId="${WI_CLIENT_ID}" \
            > "${OUT_FILE}"

          test -s "${OUT_FILE}"
          echo "MANIFEST_FILE=${OUT_FILE}" >> "$GITHUB_ENV"

          echo "Rendered manifests (first 80 lines):"
          head -n 80 "${OUT_FILE}"

      - name: Apply Helm-rendered manifests via AKS Run Command
        run: |
          set -euo pipefail
          az aks command invoke \
            -g "${RG}" \
            -n "${AKS}" \
            --file "${MANIFEST_FILE}" \
            --command 'set -euo pipefail; f="$(ls -1 *.yaml | head -n1)"; kubectl apply -n "'"${ENV_NAME}"'" -f "$f"'

      # --------------------------
      # Wait + Smoke tests
      # --------------------------
      - name: Resolve workload names from cluster (post-deploy)
        id: resolve
        run: |
          set -euo pipefail

          # Resolve deployment by instance label (this is working for you)
          DEPLOY_REF="$("$AKS_RUN" kubectl -n "${ENV_NAME}" get deploy \
            -l app.kubernetes.io/instance="${HELM_RELEASE}" -o name | head -n 1)"

          if [ -z "${DEPLOY_REF}" ]; then
            echo "ERROR: Could not resolve deployment for instance=${HELM_RELEASE} in ns=${ENV_NAME}"
            "$AKS_RUN" kubectl -n "${ENV_NAME}" get deploy --show-labels -o wide || true
            exit 1
          fi

          DEPLOY_NAME="${DEPLOY_REF#deploy/}"
          echo "deploy_name=${DEPLOY_NAME}" >> "$GITHUB_OUTPUT"

          # Try to resolve service using a few common label strategies
          SVC_REF="$("$AKS_RUN" kubectl -n "${ENV_NAME}" get svc \
            -l app.kubernetes.io/instance="${HELM_RELEASE}" -o name | head -n 1)"

          if [ -z "${SVC_REF}" ]; then
            # Fallback 1: name label
            SVC_REF="$("$AKS_RUN" kubectl -n "${ENV_NAME}" get svc \
              -l app.kubernetes.io/name="${HELM_RELEASE}" -o name | head -n 1)"
          fi

          if [ -z "${SVC_REF}" ]; then
            # Fallback 2: app label
            SVC_REF="$("$AKS_RUN" kubectl -n "${ENV_NAME}" get svc \
              -l app="${HELM_RELEASE}" -o name | head -n 1)"
          fi

          if [ -z "${SVC_REF}" ]; then
            echo "WARN: No Service found for ${HELM_RELEASE} in ns=${ENV_NAME}. Continuing without svc_name."
            echo "svc_name=" >> "$GITHUB_OUTPUT"
            echo "---- Services present (with labels) ----"
            "$AKS_RUN" kubectl -n "${ENV_NAME}" get svc --show-labels -o wide || true
          else
            SVC_NAME="${SVC_REF#service/}"
            echo "svc_name=${SVC_NAME}" >> "$GITHUB_OUTPUT"
          fi

      - name: Wait for rollout
        run: |
          set -euo pipefail
          "$AKS_RUN" kubectl -n "${ENV_NAME}" rollout status "deploy/${{ steps.resolve.outputs.deploy_name }}" --timeout=240s

      - name: Smoke test service connectivity (in-cluster)
        if: ${{ steps.resolve.outputs.svc_name != '' }}
        run: |
          set -euo pipefail
          "$AKS_RUN" kubectl -n "${ENV_NAME}" run curl-svc --image=curlimages/curl:8.10.1 -i --rm --restart=Never -- \
            sh -lc "curl -sS -D- http://${{ steps.resolve.outputs.svc_name }}.${ENV_NAME}.svc.cluster.local/ | tail -n 60"

      - name: Resolve ingress host (test)
        if: ${{ inputs.environment == 'test' }}
        id: ingress
        run: |
          set -euo pipefail
          INGRESS_REF="$("$AKS_RUN" kubectl -n "${ENV_NAME}" get ingress -l app.kubernetes.io/instance="${HELM_RELEASE}" -o name | head -n 1)"

          if [ -z "${INGRESS_REF}" ]; then
            echo "ERROR: No ingress found for instance=${HELM_RELEASE} in ns=${ENV_NAME}"
            "$AKS_RUN" kubectl -n "${ENV_NAME}" get ingress -o wide || true
            exit 1
          fi

          HOST="$("$AKS_RUN" kubectl -n "${ENV_NAME}" get "${INGRESS_REF}" -o jsonpath='{.spec.rules[0].host}' 2>/dev/null || true)"
          if [ -z "${HOST}" ]; then
            echo "ERROR: Ingress host not found on ${INGRESS_REF}"
            "$AKS_RUN" kubectl -n "${ENV_NAME}" get "${INGRESS_REF}" -o yaml | sed -n '1,160p' || true
            exit 1
          fi

          echo "ingress_host=${HOST}" >> "$GITHUB_OUTPUT"

      - name: Smoke test ingress routing (in-cluster curl via ingress)
        run: |
          set -euo pipefail

          HOST="app.${ENV_NAME}.local"
          if [ "${ENV_NAME}" = "test" ]; then
            HOST="${{ steps.ingress.outputs.ingress_host }}"
          fi

          "$AKS_RUN" sh -lc "kubectl -n ${ENV_NAME} run curl-ing --image=curlimages/curl:8.10.1 -i --rm --restart=Never -- \
            curl -sS -D- -H \"Host: ${HOST}\" http://ingress-nginx-controller.ingress-nginx.svc.cluster.local/"

      - name: Debug dump on failure
        if: failure()
        run: |
          set +e
          "$AKS_RUN" kubectl get pods -A -o wide || true
          "$AKS_RUN" kubectl -n "${ENV_NAME}" get all -o wide || true
          "$AKS_RUN" kubectl -n "${ENV_NAME}" describe deploy -l app.kubernetes.io/instance="${HELM_RELEASE}" || true
          "$AKS_RUN" kubectl -n "${ENV_NAME}" describe svc -l app.kubernetes.io/instance="${HELM_RELEASE}" || true
          "$AKS_RUN" kubectl -n "${ENV_NAME}" get endpointslices -o wide || true
          "$AKS_RUN" kubectl -n "${ENV_NAME}" get networkpolicy -o wide || true
          "$AKS_RUN" kubectl -n ingress-nginx logs deploy/ingress-nginx-controller --tail=200 || true
