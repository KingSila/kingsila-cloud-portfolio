name: Deploy AKS (Helm-Test)

on:
  workflow_dispatch:
    inputs:
      environment:
        description: "Environment to deploy"
        required: true
        type: choice
        options: [dev, test]

permissions:
  id-token: write
  contents: read

env:
  RG_DEV: rg-kingsila-dev
  AKS_DEV: aks-kingsila-dev
  RG_TEST: rg-kingsila-test
  AKS_TEST: aks-kingsila-test

  # Helm release name (keep stable)
  HELM_RELEASE: golden-app

jobs:
  deploy:
    # IMPORTANT: Private AKS requires network access from inside the VNet.
    # Use a self-hosted runner placed in the AKS VNet (or peered VNet with DNS).
    runs-on: [self-hosted, linux]

    steps:
      - uses: actions/checkout@v4

      - name: Azure Login (OIDC)
        uses: azure/login@v2
        with:
          client-id: ${{ secrets.AZURE_CLIENT_ID }}
          tenant-id: ${{ secrets.AZURE_TENANT_ID }}
          subscription-id: ${{ secrets.AZURE_SUBSCRIPTION_ID }}

      - name: Show Azure account info
        shell: bash
        run: |
          set -euo pipefail
          az account show --query "{user:user.name, type:user.type, tenant:tenantId, sub:id}" -o jsonc
          az account get-access-token --resource https://management.azure.com/ --query "expiresOn" -o tsv

      - name: Select cluster vars
        shell: bash
        run: |
          set -euo pipefail
          ENV="${{ inputs.environment }}"

          if [ "$ENV" = "dev" ]; then
            echo "RG=${RG_DEV}" >> "$GITHUB_ENV"
            echo "AKS=${AKS_DEV}" >> "$GITHUB_ENV"
            echo "WI_CLIENT_ID=${{ secrets.WI_APP_DEV_CLIENT_ID }}" >> "$GITHUB_ENV"
          else
            echo "RG=${RG_TEST}" >> "$GITHUB_ENV"
            echo "AKS=${AKS_TEST}" >> "$GITHUB_ENV"
            echo "WI_CLIENT_ID=${{ secrets.WI_APP_TEST_CLIENT_ID }}" >> "$GITHUB_ENV"
          fi

          echo "ENV_NAME=$ENV" >> "$GITHUB_ENV"

      - name: Debug selected vars
        shell: bash
        run: |
          set -euo pipefail
          echo "RG=${RG:-<missing>}"
          echo "AKS=${AKS:-<missing>}"
          echo "ENV_NAME=${ENV_NAME:-<missing>}"
          echo "HELM_RELEASE=${HELM_RELEASE:-<missing>}"
          echo "WI_CLIENT_ID=${WI_CLIENT_ID:-<missing>}"

      - name: Guard- RG/AKS set
        shell: bash
        run: |
          set -euo pipefail
          : "${RG:?missing RG}"
          : "${AKS:?missing AKS}"

      - name: Setup Helm
        uses: azure/setup-helm@v4
        with:
          version: latest

      # -----------------------------------------------------------------------
      # Helper: robust AKS Run Command wrapper (script on PATH; works across steps)
      # -----------------------------------------------------------------------
      - name: Install aks_run helper
        shell: bash
        run: |
          set -euo pipefail

          echo "RUNNER_TEMP=${RUNNER_TEMP:-<unset>}"
          mkdir -p "${RUNNER_TEMP}"
          test -w "${RUNNER_TEMP}"

          cat > "${RUNNER_TEMP}/aks_run" <<'BASH'
          #!/usr/bin/env bash
          set -euo pipefail

          : "${RG:?RG env var is required}"
          : "${AKS:?AKS env var is required}"

          if [ "$#" -lt 1 ]; then
            echo "Usage: aks_run <command...>"
            exit 2
          fi

          cmd="$*"

          out="$(az aks command invoke --only-show-errors -g "${RG}" -n "${AKS}" --command "${cmd}" -o json 2>&1)" || {
            echo "ERROR: az aks command invoke failed"
            echo "${out}"
            exit 1
          }

          python3 - <<'PY' <<<"${out}"
          import json, sys
          raw = sys.stdin.read()
          obj = json.loads(raw)
          logs = obj.get("logs") or ""
          print(str(logs).rstrip())
          PY
          BASH

              chmod +x "${RUNNER_TEMP}/aks_run"

              echo "AKS_RUN=${RUNNER_TEMP}/aks_run" >> "$GITHUB_ENV"

              echo "Created:"
              ls -la "${RUNNER_TEMP}/aks_run"


      # -----------------------------------------------------------------------
      # Cluster bootstrap (namespace always; ingress + netpol test-only)
      # -----------------------------------------------------------------------
      - name: Ensure namespace exists (dev/test)
        shell: bash
        run: |
          set -euo pipefail
          aks_run kubectl get ns "${ENV_NAME}" >/dev/null 2>&1 || aks_run kubectl create ns "${ENV_NAME}"

      - name: Install NGINX ingress controller (test)
        if: ${{ inputs.environment == 'test' }}
        shell: bash
        run: |
          set -euo pipefail
          az aks command invoke \
            -g "${RG}" \
            -n "${AKS}" \
            --file "infra/k8s/system/install-ingress-nginx.sh" \
            --command "set -euxo pipefail; ls -la; bash ./install-ingress-nginx.sh"

      - name: Apply NetworkPolicy default-deny-all (test)
        if: ${{ inputs.environment == 'test' }}
        shell: bash
        run: |
          set -euo pipefail
          az aks command invoke \
            -g "${RG}" \
            -n "${AKS}" \
            --file infra/k8s/overlays/test/networkpolicy-default-deny.yaml \
            --command "kubectl apply -f networkpolicy-default-deny.yaml"

      - name: Apply NetworkPolicy allow-dns-egress (test)
        if: ${{ inputs.environment == 'test' }}
        shell: bash
        run: |
          set -euo pipefail
          az aks command invoke \
            -g "${RG}" \
            -n "${AKS}" \
            --file infra/k8s/overlays/test/networkpolicy-allow-dns-egress.yaml \
            --command "kubectl apply -f networkpolicy-allow-dns-egress.yaml"

      - name: Create extra NetworkPolicy files (test)
        if: ${{ inputs.environment == 'test' }}
        shell: bash
        run: |
          set -euo pipefail

          cat > "$RUNNER_TEMP/networkpolicy-allow-egress-within-test.yaml" <<'YAML'
          apiVersion: networking.k8s.io/v1
          kind: NetworkPolicy
          metadata:
            name: allow-egress-within-test
            namespace: test
          spec:
            podSelector: {}
            policyTypes:
            - Egress
            egress:
            - to:
              - podSelector: {}
          YAML

          cat > "$RUNNER_TEMP/networkpolicy-allow-test-to-app.yaml" <<'YAML'
          apiVersion: networking.k8s.io/v1
          kind: NetworkPolicy
          metadata:
            name: allow-test-to-app
            namespace: test
          spec:
            podSelector:
              matchLabels:
                app.kubernetes.io/instance: golden-app
            policyTypes:
            - Ingress
            ingress:
            - from:
              - podSelector: {}
              ports:
              - protocol: TCP
                port: 8080
          YAML

      - name: Apply NetworkPolicy allow-egress-within-namespace (test)
        if: ${{ inputs.environment == 'test' }}
        shell: bash
        run: |
          set -euo pipefail
          az aks command invoke \
            -g "${RG}" \
            -n "${AKS}" \
            --file "${RUNNER_TEMP}/networkpolicy-allow-egress-within-test.yaml" \
            --command "kubectl apply -f networkpolicy-allow-egress-within-test.yaml"

      - name: Apply NetworkPolicy allow-test-to-app (test)
        if: ${{ inputs.environment == 'test' }}
        shell: bash
        run: |
          set -euo pipefail
          az aks command invoke \
            -g "${RG}" \
            -n "${AKS}" \
            --file "${RUNNER_TEMP}/networkpolicy-allow-test-to-app.yaml" \
            --command "kubectl apply -f networkpolicy-allow-test-to-app.yaml"

      - name: Apply NetworkPolicy allow-ingress-nginx-to-app (test)
        if: ${{ inputs.environment == 'test' }}
        shell: bash
        run: |
          set -euo pipefail
          az aks command invoke \
            -g "${RG}" \
            -n "${AKS}" \
            --file infra/k8s/overlays/test/networkpolicy-allow-ingress-nginx-to-app.yaml \
            --command "kubectl apply -f networkpolicy-allow-ingress-nginx-to-app.yaml"

      # --------------------------
      # Helm render gate (runner)
      # --------------------------
      - name: Helm render validation (runner)
        shell: bash
        run: |
          set -euo pipefail
          helm template "${HELM_RELEASE}" ./infra/k8s/golden-app/charts \
            --namespace "${ENV_NAME}" \
            -f ./infra/k8s/golden-app/charts/values.yaml \
            -f ./infra/k8s/${ENV_NAME}/values.yaml \
            --set workloadIdentity.clientId="${WI_CLIENT_ID}" \
            --debug > /dev/null

      # --------------------------
      # Render Helm chart to manifests (runner) + Apply (in-cluster)
      # --------------------------
      - name: Render Helm chart to manifests (runner)
        shell: bash
        run: |
          set -euo pipefail
          OUT_FILE="$RUNNER_TEMP/helm-rendered.yaml"

          helm template "${HELM_RELEASE}" ./infra/k8s/golden-app/charts \
            --namespace "${ENV_NAME}" \
            -f ./infra/k8s/golden-app/charts/values.yaml \
            -f ./infra/k8s/${ENV_NAME}/values.yaml \
            --set workloadIdentity.clientId="${WI_CLIENT_ID}" \
            > "${OUT_FILE}"

          test -s "${OUT_FILE}"
          echo "MANIFEST_FILE=${OUT_FILE}" >> "$GITHUB_ENV"

          echo "Rendered manifests (first 80 lines):"
          head -n 80 "${OUT_FILE}"

      - name: Apply Helm-rendered manifests via AKS Run Command
        shell: bash
        run: |
          set -euo pipefail
          az aks command invoke \
            -g "${RG}" \
            -n "${AKS}" \
            --file "${MANIFEST_FILE}" \
            --command "set -euo pipefail; f=$(ls -1 *.yaml | head -n1); test -s \"$f\"; kubectl apply -f \"$f\""

      # --------------------------
      # Wait + Smoke tests (robust name resolution)
      # --------------------------
      - name: Resolve workload names from cluster (post-deploy)
        id: resolve
        shell: bash
        run: |
          set -euo pipefail
          source "$RUNNER_TEMP/aks_run.sh"

          DEPLOY_REF="$(aks_run "kubectl -n ${ENV_NAME} get deploy -l app.kubernetes.io/instance=${HELM_RELEASE} -o name | head -n 1")"
          SVC_REF="$(aks_run "kubectl -n ${ENV_NAME} get svc   -l app.kubernetes.io/instance=${HELM_RELEASE} -o name | head -n 1")"

          if [ -z "${DEPLOY_REF}" ] || [ -z "${SVC_REF}" ]; then
            echo "ERROR: Could not resolve deploy/service for instance=${HELM_RELEASE} in ns=${ENV_NAME}"
            echo "--- debug: deployments ---"
            aks_run kubectl -n "${ENV_NAME}" get deploy -l app.kubernetes.io/instance="${HELM_RELEASE}" -o wide || true
            echo "--- debug: services ---"
            aks_run kubectl -n "${ENV_NAME}" get svc -l app.kubernetes.io/instance="${HELM_RELEASE}" -o wide || true
            exit 1
          fi

          DEPLOY_NAME="${DEPLOY_REF#deploy/}"
          SVC_NAME="${SVC_REF#service/}"

          echo "deploy_name=${DEPLOY_NAME}" >> "$GITHUB_OUTPUT"
          echo "svc_name=${SVC_NAME}" >> "$GITHUB_OUTPUT"

      - name: Wait for rollout
        shell: bash
        run: |
          set -euo pipefail
          source "$RUNNER_TEMP/aks_run.sh"
          aks_run "kubectl -n ${ENV_NAME} rollout status deploy/${{ steps.resolve.outputs.deploy_name }} --timeout=240s"

      - name: Smoke test service connectivity (in-cluster)
        shell: bash
        run: |
          set -euo pipefail
          source "$RUNNER_TEMP/aks_run.sh"
          aks_run "kubectl -n ${ENV_NAME} run curl-svc --image=curlimages/curl:8.10.1 -i --rm --restart=Never -- \
            sh -lc \"curl -sS -D- http://${{ steps.resolve.outputs.svc_name }}.${ENV_NAME}.svc.cluster.local/ | tail -n 60\""

      # --------------------------
      # Resolve ingress host from the cluster (test)
      # --------------------------
      - name: Resolve ingress host (test)
        if: ${{ inputs.environment == 'test' }}
        id: ingress
        shell: bash
        run: |
          set -euo pipefail
          source "$RUNNER_TEMP/aks_run.sh"

          INGRESS_REF="$(aks_run "kubectl -n ${ENV_NAME} get ingress -l app.kubernetes.io/instance=${HELM_RELEASE} -o name | head -n 1")"
          if [ -z "$INGRESS_REF" ]; then
            echo "ERROR: No ingress found for instance=${HELM_RELEASE} in ns=${ENV_NAME}"
            aks_run kubectl -n "${ENV_NAME}" get ingress -o wide || true
            exit 1
          fi

          HOST="$(aks_run kubectl -n "${ENV_NAME}" get "${INGRESS_REF}" -o jsonpath='{.spec.rules[0].host}' 2>/dev/null || true)"
          if [ -z "$HOST" ]; then
            echo "ERROR: Ingress host not found on ${INGRESS_REF}"
            aks_run kubectl -n "${ENV_NAME}" get "${INGRESS_REF}" -o yaml | sed -n '1,160p' || true
            exit 1
          fi

          INGRESS_NAME="${INGRESS_REF#ingress/}"

          echo "ingress_name=${INGRESS_NAME}" >> "$GITHUB_OUTPUT"
          echo "ingress_host=${HOST}" >> "$GITHUB_OUTPUT"

      - name: Smoke test ingress routing (in-cluster curl via ingress)
        shell: bash
        run: |
          set -euo pipefail
          source "$RUNNER_TEMP/aks_run.sh"

          HOST="app.${ENV_NAME}.local"
          if [ "${ENV_NAME}" = "test" ]; then
            HOST="${{ steps.ingress.outputs.ingress_host }}"
          fi

          aks_run "HOST='${HOST}' sh -lc \"kubectl -n ${ENV_NAME} run curl-ing --image=curlimages/curl:8.10.1 -i --rm --restart=Never -- \
            curl -sS -D- -H \\\"Host: \\$HOST\\\" http://ingress-nginx-controller.ingress-nginx.svc.cluster.local/\""

      - name: Debug dump on failure
        if: failure()
        shell: bash
        run: |
          set +e
          source "$RUNNER_TEMP/aks_run.sh"
          aks_run "kubectl get pods -A -o wide || true"
          aks_run "kubectl -n ${ENV_NAME} get all -o wide || true"
          aks_run "kubectl -n ${ENV_NAME} describe deploy -l app.kubernetes.io/instance=${HELM_RELEASE} || true"
          aks_run "kubectl -n ${ENV_NAME} describe svc -l app.kubernetes.io/instance=${HELM_RELEASE} || true"
          aks_run "kubectl -n ${ENV_NAME} get endpointslices -o wide || true"
          aks_run "kubectl -n ${ENV_NAME} get networkpolicy -o wide || true"
          aks_run "kubectl -n ingress-nginx logs deploy/ingress-nginx-controller --tail=200 || true"
